@inproceedings{Colavito-2023,
 abstract = {This paper describes our participation in the tool competition organized in the scope of the 1st International Workshop on Natural Language-based Software Engineering. We propose a supervised approach relying on fine-tuned BERT-based language models for the automatic classification of GitHub issues. We experimented with different pre-trained models, achieving the best performance with fine-tuned RoBERTa (F1 = .8591).},
 address = {New York, NY, USA},
 author = {Colavito, Giuseppe and Lanubile, Filippo and Novielli, Nicole},
 booktitle = {Proceedings of the 1st International Workshop on Natural Language-based Software Engineering},
 doi = {10.1145/3528588.3528659},
 isbn = {978-1-4503-9343-0},
 keywords = {\,BERT,deep learning,issue classification,labeling unstructured data,software maintenance and evolution},
 month = {February},
 pages = {29--32},
 publisher = {Association for Computing Machinery},
 series = {NLBSE '22},
 title = {Issue Report Classification Using Pre-Trained Language Models},
 urldate = {2024-01-25},
 year = {2023}
}
